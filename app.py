# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import vertexai
from vertexai.preview.generative_models import GenerativeModel
import PyPDF2
import docx
import re
import io

# --- CONFIGURACI√ìN DE LA P√ÅGINA DE STREAMLIT ---
st.set_page_config(
    page_title="Generador y Auditor de √çtems con IA (Vertex AI)",
    page_icon="üß†",
    layout="wide"
)

# --- VARIABLES DE ENTORNO ---
# Estas variables se configuran en el entorno de despliegue (Cloud Run).
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID")
GCP_LOCATION = os.environ.get("GCP_LOCATION")

# --- INICIALIZACI√ìN DE VERTEX AI ---
# Se ejecuta una sola vez y usa la autenticaci√≥n del entorno de Cloud Run.
if 'vertex_initialized' not in st.session_state:
    try:
        if GCP_PROJECT_ID and GCP_LOCATION:
            vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
            st.session_state.vertex_initialized = True
            st.sidebar.success("‚úÖ Conectado a Vertex AI.")
        else:
            st.sidebar.error("Variables de entorno GCP_PROJECT_ID o GCP_LOCATION no configuradas.")
            st.session_state.vertex_initialized = False
    except Exception as e:
        st.sidebar.error(f"Error al inicializar Vertex AI: {e}")
        st.session_state.vertex_initialized = False


# --- Funciones de Lectura de Archivos ---
@st.cache_data
def leer_excel_cargado(uploaded_file):
    if uploaded_file is not None:
        try:
            df = pd.read_excel(uploaded_file)
            st.sidebar.success(f"Archivo Excel '{uploaded_file.name}' cargado exitosamente.")
            return df
        except Exception as e:
            st.sidebar.error(f"Ocurri√≥ un error al leer el archivo Excel: {e}")
            return None
    return None

@st.cache_data
def leer_pdf_cargado(uploaded_file):
    if uploaded_file is not None:
        try:
            texto_pdf = ""
            reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
            for page_num in range(len(reader.pages)):
                texto_pdf += reader.pages[page_num].extract_text()
            st.sidebar.success(f"Archivo PDF '{uploaded_file.name}' le√≠do exitosamente.")
            return texto_pdf
        except Exception as e:
            st.sidebar.error(f"Ocurri√≥ un error al leer el archivo PDF: {e}")
            return ""
    return ""

# --- Funci√≥n para obtener la descripci√≥n de la taxonom√≠a de Bloom ---
def get_descripcion_bloom(proceso_cognitivo_elegido):
    descripcion_bloom_map = {
        "RECORDAR": "Recuperar informaci√≥n relevante desde la memoria de largo plazo.",
        "COMPRENDER": "Construir significado a partir de informaci√≥n mediante interpretaci√≥n, resumen, explicaci√≥n u otras tareas.",
        "APLICAR": "Usar procedimientos en situaciones conocidas o nuevas.",
        "ANALIZAR": "Descomponer informaci√≥n y examinar relaciones entre partes.",
        "EVALUAR": "Emitir juicios basados en criterios para valorar ideas o soluciones.",
        "CREAR": "Generar nuevas ideas, productos o formas de reorganizar informaci√≥n."
    }
    return descripcion_bloom_map.get(str(proceso_cognitivo_elegido).upper(), "Descripci√≥n no disponible.")

# --- Funci√≥n para generar texto con Vertex AI ---
def generar_texto_con_llm(model_name, prompt):
    """
    Genera texto usando un modelo de Gemini a trav√©s de la infraestructura de Vertex AI.
    """
    if 'vertex_initialized' not in st.session_state or not st.session_state.vertex_initialized:
        st.error("Vertex AI no est√° inicializado. Verifica la configuraci√≥n.")
        return None
    
    try:
        modelo = GenerativeModel(model_name)
        response = modelo.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Error al llamar al modelo '{model_name}' en Vertex AI: {e}")
        return None

# --- Funci√≥n para auditar el √≠tem generado ---
def auditar_item_con_llm(model_name, item_generado, grado, area, asignatura, estacion,
                         proceso_cognitivo, nanohabilidad, microhabilidad,
                         competencia_nanohabilidad, contexto_educativo, manual_reglas_texto="", descripcion_bloom="", grafico_necesario="", descripcion_grafico="", prompt_auditor_adicional=""):
    auditoria_prompt = f"""
    Eres un experto en validaci√≥n de √≠tems educativos, especializado en pruebas tipo ICFES y las directrices del equipo IMPROVE.
    Tu tarea es AUDITAR RIGUROSAMENTE el siguiente √≠tem generado por un modelo de lenguaje.
    Debes verificar que el √≠tem cumpla con TODOS los siguientes criterios.

    --- CRITERIOS DE AUDITOR√çA ---
    1.  **Formato del Enunciado:** ¬øEl enunciado est√° formulado como pregunta clara y directa?
    2.  **N√∫mero de Opciones:** ¬øHay exactamente 4 opciones (A, B, C, D)?
    3.  **Respuesta Correcta Indicada:** ¬øLa secci√≥n 'RESPUESTA CORRECTA:' est√° claramente indicada?
    4.  **Dise√±o de Justificaciones:** ¬øLas justificaciones siguen el formato requerido (explicaci√≥n para la correcta, an√°lisis de error para las incorrectas)?
    5.  **Estilo y Restricciones:** ¬øNo se usan negaciones mal redactadas, nombres reales, marcas, etc.?
    6.  **Alineaci√≥n del Contenido:** ¬øEl √≠tem est√° alineado EXCLUSIVAMENTE con los siguientes elementos?
        * Grado: {grado}
        * √Årea: {area}
        * Asignatura: {asignatura}
        * Estaci√≥n o unidad tem√°tica: {estacion}
        * Proceso Cognitivo (Taxonom√≠a de Bloom): {proceso_cognitivo} (descripci√≥n: "{descripcion_bloom}")
        * Nanohabilidad: {nanohabilidad}
        * Microhabilidad: {microhabilidad}
        * Competencia: {competencia_nanohabilidad}
        * Nivel educativo: {contexto_educativo}
    7.  **Gr√°fico (si aplica):** Si el √≠tem indica que requiere un gr√°fico, ¬øla descripci√≥n es clara?
        * Gr√°fico Necesario: {grafico_necesario}
        * Descripci√≥n del Gr√°fico: {descripcion_grafico if grafico_necesario == 'S√ç' else 'N/A'}

    --- MANUAL DE REGLAS ADICIONAL ---
    {manual_reglas_texto}
    -----------------------------------

    --- INSTRUCCIONES ADICIONALES PARA LA AUDITOR√çA ---
    {prompt_auditor_adicional if prompt_auditor_adicional else "No se proporcionaron instrucciones adicionales."}
    ---------------------------------------------------

    √çTEM A AUDITAR:
    --------------------
    {item_generado}
    --------------------

    Devuelve tu auditor√≠a con este formato estructurado:

    VALIDACI√ìN DE CRITERIOS:
    - Formato del Enunciado: [‚úÖ / ‚ùå] + Comentario (si ‚ùå)
    - N√∫mero de Opciones (4): [‚úÖ / ‚ùå]
    - Respuesta Correcta Indicada: [‚úÖ / ‚ùå]
    - Dise√±o de Justificaciones: [‚úÖ / ‚ö†Ô∏è / ‚ùå] + Observaciones (si ‚ö†Ô∏è/‚ùå)
    - Estilo y Restricciones: [‚úÖ / ‚ö†Ô∏è / ‚ùå] + Observaciones (si ‚ö†Ô∏è/‚ùå)
    - Alineaci√≥n del Contenido: [‚úÖ / ‚ùå] + Comentario (si ‚ùå)
    - Gr√°fico (si aplica): [‚úÖ / ‚ö†Ô∏è / ‚ùå] + Observaciones (si ‚ö†Ô∏è/‚ùå)

    DICTAMEN FINAL:
    [‚úÖ CUMPLE TOTALMENTE / ‚ö†Ô∏è CUMPLE PARCIALMENTE / ‚ùå RECHAZADO]

    OBSERVACIONES FINALES:
    [Explica de forma concisa qu√© aspectos necesitan mejora, si el dictamen no es ‚úÖ.]
    """
    return generar_texto_con_llm(model_name, auditoria_prompt), auditoria_prompt

# --- Funci√≥n principal para generar y auditar preguntas ---
def generar_pregunta_con_seleccion(gen_model_name, audit_model_name,
                                   fila_datos, criterios_generacion, manual_reglas_texto="",
                                   informacion_adicional_usuario="",
                                   prompt_bloom_adicional="", prompt_construccion_adicional="", prompt_especifico_adicional="",
                                   prompt_auditor_adicional="",
                                   contexto_general_estacion=""):
    tipo_pregunta = criterios_generacion.get("tipo_pregunta", "opci√≥n m√∫ltiple con 4 opciones")
    dificultad = criterios_generacion.get("dificultad", "media")
    contexto_educativo = criterios_generacion.get("contexto_educativo", "general")
    formato_justificacion = criterios_generacion.get("formato_justificacion", """
        ‚Ä¢ Justificaci√≥n correcta: debe explicar el razonamiento o proceso cognitivo (NO por descarte).
        ‚Ä¢ Justificaciones incorrectas: deben redactarse como: ‚ÄúEl estudiante podr√≠a escoger la opci√≥n X porque‚Ä¶ Sin embargo, esto es incorrecto porque‚Ä¶‚Äù
    """)
    
    grado_elegido = fila_datos.get('GRADO', 'no especificado')
    area_elegida = fila_datos.get('√ÅREA', 'no especificada')
    asignatura_elegida = fila_datos.get('ASIGNATURA', 'no especificada')
    estacion_elegida = fila_datos.get('ESTACI√ìN', 'no especificada')
    proceso_cognitivo_elegido = fila_datos.get('PROCESO COGNITIVO', 'no especificado')
    nanohabilidad_elegida = fila_datos.get('NANOHABILIDAD', 'no especificada')
    microhabilidad_elegida = fila_datos.get('MICROHABILIDAD', 'no especificada')
    competencia_nanohabilidad_elegida = fila_datos.get('COMPETENCIA NANOHABILIDAD', 'no especificada')

    descripcion_bloom = get_descripcion_bloom(proceso_cognitivo_elegido)

    current_item_text = ""
    auditoria_status = "‚ùå RECHAZADO"
    audit_observations = ""
    max_refinement_attempts = 5
    attempt = 0
    grafico_necesario = "NO"
    descripcion_grafico = ""
    item_final_data = None
    full_generation_prompt = ""
    full_auditor_prompt = ""

    classification_details = {
        "Grado": grado_elegido, "√Årea": area_elegida, "Asignatura": asignatura_elegida,
        "Estaci√≥n": estacion_elegida, "Proceso Cognitivo": proceso_cognitivo_elegido,
        "Nanohabilidad": nanohabilidad_elegida, "Microhabilidad": microhabilidad_elegida,
        "Competencia Nanohabilidad": competencia_nanohabilidad_elegida
    }

    while auditoria_status != "‚úÖ CUMPLE TOTALMENTE" and attempt < max_refinement_attempts:
        attempt += 1
        
        prompt_content_for_llm = f"""
        Eres un dise√±ador experto en √≠tems de evaluaci√≥n educativa, especializado en pruebas tipo ICFES.
        Tu tarea es construir un √≠tem de {tipo_pregunta} con una √∫nica respuesta correcta.

        --- CONTEXTO Y PAR√ÅMETROS DEL √çTEM ---
        - Grado: {grado_elegido}
        - √Årea: {area_elegida}
        - Asignatura: {asignatura_elegida}
        - Estaci√≥n o unidad tem√°tica: {estacion_elegida}
        - Proceso cognitivo (Taxonom√≠a de Bloom): {proceso_cognitivo_elegido}
        - Descripci√≥n del proceso cognitivo: "{descripcion_bloom}"
        
        --- PROMPT ADICIONAL: TAXONOM√çA DE BLOOM / PROCESOS COGNITIVOS ---
        {prompt_bloom_adicional if prompt_bloom_adicional else "No se proporcionaron prompts adicionales."}
        ------------------------------------------------------------------

        - Nanohabilidad (foco principal): {nanohabilidad_elegida}
        - Nivel educativo: {contexto_educativo}
        - Dificultad deseada: {dificultad}

        --- CONTEXTO GENERAL DE LA ESTACI√ìN (si aplica) ---
        {f"Considera este contexto general: {contexto_general_estacion}" if contexto_general_estacion else "Genera un contexto individual para este √≠tem."}
        ----------------------------------------------------

        --- INSTRUCCIONES PARA LA CONSTRUCCI√ìN ---
        CONTEXTO: Incluye una situaci√≥n relevante para el grado y √°rea.
        ENUNCIADO: Formula una pregunta clara y directa. Si usas negaciones, res√°ltalas en MAY√öSCULAS Y NEGRITA.
        OPCIONES: Escribe exactamente cuatro opciones (A, B, C, D). Solo una correcta. Los distractores deben ser cre√≠bles.
        JUSTIFICACIONES: {formato_justificacion}

        --- PROMPT ADICIONAL: REGLAS GENERALES DE CONSTRUCCI√ìN ---
        {prompt_construccion_adicional if prompt_construccion_adicional else "No se proporcionaron prompts adicionales."}
        ---------------------------------------------------------

        --- REGLAS ADICIONALES DEL MANUAL ---
        Aplica estrictamente las directrices del siguiente manual:
        {manual_reglas_texto}
        ----------------------------------------------------

        --- INFORMACI√ìN ADICIONAL DEL USUARIO ---
        {informacion_adicional_usuario if informacion_adicional_usuario else "No se proporcion√≥ informaci√≥n adicional."}
        ---------------------------------------------------------------------------
        
        --- PROMPT ADICIONAL: COSAS ESPEC√çFICAS A TENER EN CUENTA ---
        {prompt_especifico_adicional if prompt_especifico_adicional else "No se proporcionaron prompts adicionales."}
        ----------------------------------------------------------

        --- DATO CLAVE PARA LA CONSTRUCCI√ìN ---
        Basa el √≠tem en la siguiente nanohabilidad: "{nanohabilidad_elegida}"

        --- INSTRUCCIONES DE SALIDA PARA GR√ÅFICO ---
        Despu√©s de las justificaciones, incluye:
        GRAFICO_NECESARIO: [S√ç/NO]
        DESCRIPCION_GRAFICO: [Si es S√ç, descripci√≥n detallada. Si es NO, escribe N/A.]

        --- FORMATO ESPERADO DE SALIDA ---
        PREGUNTA: [Enunciado]
        A. [Opci√≥n A]
        B. [Opci√≥n B]
        C. [Opci√≥n C]
        D. [Opci√≥n D]
        RESPUESTA CORRECTA: [Letra]
        JUSTIFICACIONES:
        A. [Justificaci√≥n A]
        B. [Justificaci√≥n B]
        C. [Justificaci√≥n C]
        D. [Justificaci√≥n D]
        GRAFICO_NECESARIO: [S√ç/NO]
        DESCRIPCION_GRAFICO: [Descripci√≥n o N/A]
        """
        
        if attempt > 1:
            prompt_content_for_llm += f"""
            --- RETROALIMENTACI√ìN DE AUDITOR√çA PARA REFINAMIENTO ---
            El √≠tem anterior no cumpli√≥ los criterios. Revisa estas observaciones y mejora el √≠tem:
            Observaciones del Auditor: {audit_observations}
            --- √çTEM ANTERIOR A REFINAR ---
            {current_item_text}
            -------------------------------
            """
        
        full_generation_prompt = prompt_content_for_llm

        try:
            with st.spinner(f"Generando contenido con IA ({gen_model_name}, Intento {attempt})..."):
                full_llm_response = generar_texto_con_llm(gen_model_name, prompt_content_for_llm)
                
                if full_llm_response is None:
                    auditoria_status = "‚ùå RECHAZADO (Error de Generaci√≥n)"
                    audit_observations = "El modelo de generaci√≥n no pudo producir una respuesta."
                    break
                
                item_and_graphic_match = re.search(r"(PREGUNTA:.*?)(GRAFICO_NECESARIO:\s*(S√ç|NO).*?DESCRIPCION_GRAFICO:.*)", full_llm_response, re.DOTALL)
                
                if item_and_graphic_match:
                    current_item_text = item_and_graphic_match.group(1).strip()
                    grafico_info_block = item_and_graphic_match.group(2).strip()
                    
                    grafico_necesario_match = re.search(r"GRAFICO_NECESARIO:\s*(S√ç|NO)", grafico_info_block)
                    grafico_necesario = grafico_necesario_match.group(1).strip() if grafico_necesario_match else "NO"

                    descripcion_grafico_match = re.search(r"DESCRIPCION_GRAFICO:\s*(.*)", grafico_info_block, re.DOTALL)
                    descripcion_grafico = descripcion_grafico_match.group(1).strip() if descripcion_grafico_match else ""
                    if descripcion_grafico.upper() == 'N/A':
                        descripcion_grafico = ""
                else:
                    current_item_text = full_llm_response
                    grafico_necesario = "NO"
                    descripcion_grafico = ""
                    st.warning("No se pudo parsear el formato de gr√°fico. Asumiendo que no se requiere.")

            with st.spinner(f"Auditando √≠tem ({audit_model_name}, Intento {attempt})..."):
                auditoria_resultado, full_auditor_prompt = auditar_item_con_llm(
                    audit_model_name,
                    item_generado=current_item_text,
                    grado=grado_elegido, area=area_elegida, asignatura=asignatura_seleccionada, estacion=estacion_elegida,
                    proceso_cognitivo=proceso_cognitivo_seleccionado, nanohabilidad=nanohabilidad_seleccionada,
                    microhabilidad=microhabilidad_elegida, competencia_nanohabilidad=competencia_nanohabilidad_elegida,
                    contexto_educativo=contexto_educativo, manual_reglas_texto=manual_reglas_texto,
                    descripcion_bloom=descripcion_bloom,
                    grafico_necesario=grafico_necesario,
                    descripcion_grafico=descripcion_grafico,
                    prompt_auditor_adicional=prompt_auditor_adicional
                )
                if auditoria_resultado is None:
                    auditoria_status = "‚ùå RECHAZADO (Error de Auditor√≠a)"
                    audit_observations = "El modelo de auditor√≠a no pudo producir una respuesta."
                    break

            dictamen_final_match = re.search(r"DICTAMEN FINAL:\s*\[(.*?)]", auditoria_resultado, re.DOTALL)
            auditoria_status = dictamen_final_match.group(1).strip() if dictamen_final_match else "‚ùå RECHAZADO (no se pudo extraer dictamen)"
            
            observaciones_start = auditoria_resultado.find("OBSERVACIONES FINALES:")
            audit_observations = auditoria_resultado[observaciones_start + len("OBSERVACIONES FINALES:"):].strip() if observaciones_start != -1 else "No se pudieron extraer observaciones."
            
            item_final_data = {
                "item_text": current_item_text, "classification": classification_details,
                "grafico_necesario": grafico_necesario, "descripcion_grafico": descripcion_grafico,
                "final_audit_status": auditoria_status, "final_audit_observations": audit_observations,
                "generation_prompt_used": full_generation_prompt, "auditor_prompt_used": full_auditor_prompt
            }

            if auditoria_status == "‚úÖ CUMPLE TOTALMENTE":
                break
        
        except Exception as e:
            audit_observations = f"Error t√©cnico durante la generaci√≥n: {e}"
            auditoria_status = "‚ùå RECHAZADO (error t√©cnico)"
            item_final_data = {
                "item_text": current_item_text if current_item_text else "No se pudo generar el √≠tem.",
                "classification": classification_details, "grafico_necesario": "NO", "descripcion_grafico": "",
                "final_audit_status": auditoria_status, "final_audit_observations": audit_observations,
                "generation_prompt_used": full_generation_prompt, "auditor_prompt_used": full_auditor_prompt
            }
            break

    return item_final_data

# --- Funci√≥n para exportar preguntas a un documento Word ---
def exportar_a_word(preguntas_procesadas_list):
    doc = docx.Document()
    doc.add_heading('Preguntas Generadas y Auditadas', level=1)
    doc.add_paragraph('Este documento contiene los √≠tems generados por el sistema de IA y sus resultados de auditor√≠a.\n')

    if not preguntas_procesadas_list:
        doc.add_paragraph('No se procesaron √≠tems para este informe.')

    for i, item_data in enumerate(preguntas_procesadas_list):
        doc.add_heading(f'√çtem #{i+1}', level=2)
        doc.add_paragraph('--- Clasificaci√≥n del √çtem ---')
        for key, value in item_data["classification"].items():
            p = doc.add_paragraph()
            p.add_run(f"{key}: ").bold = True
            p.add_run(str(value))
        
        doc.add_paragraph('\n' + item_data["item_text"])

        if item_data.get("grafico_necesario") == "S√ç" and item_data.get("descripcion_grafico"):
            doc.add_paragraph()
            p = doc.add_paragraph()
            p.add_run("--- Gr√°fico Sugerido ---").bold = True
            doc.add_paragraph(f"**Tipo y Descripci√≥n del Gr√°fico:** {item_data['descripcion_grafico']}\n")

        doc.add_paragraph()
        p = doc.add_paragraph()
        p.add_run("--- Resultado Final de Auditor√≠a ---").bold = True
        doc.add_paragraph(f"**DICTAMEN FINAL:** {item_data.get('final_audit_status', 'N/A')}")
        doc.add_paragraph(f"**OBSERVACIONES FINALES:** {item_data.get('final_audit_observations', 'N/A')}\n")
        
        doc.add_page_break()

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# --- Interfaz de Usuario Principal de Streamlit ---
st.title("üìö Generador y Auditor de √≠tems para el proyecto SUMUN üß†")
st.markdown("Esta aplicaci√≥n genera √≠tems de selecci√≥n m√∫ltiple y audita su calidad, usando la infraestructura de Vertex AI.")

# Secci√≥n de Carga de Archivos Global (Excel y PDF)
st.sidebar.header("Carga de Archivos Global")
uploaded_excel_file = st.sidebar.file_uploader("Sube tu archivo Excel (ESTRUCTURA_TOTAL.xlsx)", type=["xlsx"])
uploaded_pdf_file = st.sidebar.file_uploader("Sube tu archivo PDF (Manual_construccion_pruebas_IMProve.pdf)", type=["pdf"])

df_datos = None
manual_reglas_texto = ""

if uploaded_excel_file:
    df_datos = leer_excel_cargado(uploaded_excel_file)
if uploaded_pdf_file:
    manual_reglas_texto = leer_pdf_cargado(uploaded_pdf_file)
    max_manual_length = 15000
    if len(manual_reglas_texto) > max_manual_length:
        st.sidebar.warning(f"Manual truncado a {max_manual_length} caracteres.")
        manual_reglas_texto = manual_reglas_texto[:max_manual_length]
    st.sidebar.info(f"Manual de reglas cargado ({len(manual_reglas_texto)} caracteres).")

# --- L√≥gica principal de Generaci√≥n y Auditor√≠a de √çtems ---
st.header("Generaci√≥n y Auditor√≠a de √çtems")

if df_datos is None:
    st.info("Para comenzar, sube tu archivo Excel en la barra lateral.")
elif 'vertex_initialized' not in st.session_state or not st.session_state.vertex_initialized:
    st.warning("La conexi√≥n con Vertex AI no se ha establecido. Revisa la configuraci√≥n del entorno.")
else:
    st.subheader("Selecciona los Criterios para la Generaci√≥n")
    
    # Filtros de selecci√≥n
    all_grades = df_datos['GRADO'].dropna().unique().tolist()
    grado_seleccionado = st.selectbox("Grado", sorted(all_grades))
    df_filtrado_grado = df_datos[df_datos['GRADO'].astype(str) == str(grado_seleccionado)]
    
    all_areas = df_filtrado_grado['√ÅREA'].dropna().unique().tolist()
    area_seleccionada = st.selectbox("√Årea", sorted(all_areas))
    df_filtrado_area = df_filtrado_grado[df_filtrado_grado['√ÅREA'] == area_seleccionada]
    
    all_asignaturas = df_filtrado_area['ASIGNATURA'].dropna().unique().tolist()
    asignatura_seleccionada = st.selectbox("Asignatura", sorted(all_asignaturas))
    df_filtrado_asignatura = df_filtrado_area[df_filtrado_area['ASIGNATURA'] == asignatura_seleccionada]
    
    all_estaciones = df_filtrado_asignatura['ESTACI√ìN'].dropna().unique().tolist()
    estacion_seleccionada = st.selectbox("Estaci√≥n", sorted(all_estaciones))
    df_filtrado_estacion = df_filtrado_asignatura[df_filtrado_asignatura['ESTACI√ìN'] == estacion_seleccionada]
    
    st.subheader("Modo de Generaci√≥n de √çtems")
    generate_all_for_station = st.checkbox("Generar TODOS los √≠tems de esta Estaci√≥n")
    
    contexto_general_estacion = ""
    if generate_all_for_station:
        contexto_general_estacion = st.text_area("Escribe una idea para el contexto general de la estaci√≥n (opcional, la IA puede crearlo):", height=150)

    proceso_cognitivo_seleccionado = None
    nanohabilidad_seleccionada = None
    df_item_seleccionado = None

    if not generate_all_for_station:
        all_procesos = df_filtrado_estacion['PROCESO COGNITIVO'].dropna().unique().tolist()
        proceso_cognitivo_seleccionado = st.selectbox("Proceso Cognitivo", sorted(all_procesos))
        df_filtrado_proceso = df_filtrado_estacion[df_filtrado_estacion['PROCESO COGNITIVO'] == proceso_cognitivo_seleccionado]
        
        all_nanohabilidades = df_filtrado_proceso['NANOHABILIDAD'].dropna().unique().tolist()
        nanohabilidad_seleccionada = st.selectbox("Nanohabilidad", sorted(all_nanohabilidades))
        df_item_seleccionado = df_filtrado_proceso[df_filtrado_proceso['NANOHABILIDAD'] == nanohabilidad_seleccionada]
    else:
        df_item_seleccionado = df_filtrado_estacion.copy()

    if df_item_seleccionado.empty:
        st.error("No hay datos para generar con los filtros actuales.")
    else:
        informacion_adicional_usuario = ""
        if not generate_all_for_station:
            informacion_adicional_usuario = st.text_area("Contexto adicional para este √≠tem individual (Opcional):")

        st.subheader("Personaliza con Prompts Adicionales (Opcional)")
        use_additional_prompts = st.checkbox("Activar Prompts Adicionales")
        prompt_bloom_adicional, prompt_construccion_adicional, prompt_especifico_adicional, prompt_auditor_adicional = "", "", "", ""

        if use_additional_prompts:
            # ... (c√≥digo para los prompts adicionales, se mantiene igual)

        st.subheader("Configuraci√≥n de Modelos de IA (Vertex AI)")
        col1, col2 = st.columns(2)
        with col1:
            gen_model_name = st.selectbox("Modelo para Generaci√≥n", ["gemini-2.0-flash", "gemini-2.5-pro", "gemini-2.0-flash-lite"])
        with col2:
            audit_model_name = st.selectbox("Modelo para Auditor√≠a", ["gemini-2.0-flash-lite", "gemini-2.0-flash", "gemini-2.5-pro"])

        if st.button("Generar y Auditar √çtem(s)"):
            criterios_para_preguntas = {
                "tipo_pregunta": "opci√≥n m√∫ltiple con 4 opciones", "dificultad": "media",
                "contexto_educativo": "estudiantes de preparatoria (bachillerato)",
                "formato_justificacion": """
                    ‚Ä¢ Justificaci√≥n correcta: debe explicar el razonamiento (NO por descarte).
                    ‚Ä¢ Justificaciones incorrectas: deben redactarse como: ‚ÄúEl estudiante podr√≠a escoger la opci√≥n X porque‚Ä¶ Sin embargo, esto es incorrecto porque‚Ä¶‚Äù
                """
            }
            processed_items_list = []

            if generate_all_for_station:
                st.info(f"Generando √≠tems para la Estaci√≥n: {estacion_seleccionada}")
                unique_procesos = df_item_seleccionado[['PROCESO COGNITIVO', 'NANOHABILIDAD', 'MICROHABILIDAD', 'COMPETENCIA NANOHABILIDAD']].drop_duplicates().to_dict('records')
                progress_bar = st.progress(0)
                
                for i, item_spec_row in enumerate(unique_procesos):
                    st.write(f"Procesando {i+1}/{len(unique_procesos)}: {item_spec_row['PROCESO COGNITIVO']}...")
                    current_fila_datos = {'GRADO': grado_seleccionado, '√ÅREA': area_seleccionada, 'ASIGNATURA': asignatura_seleccionada, 'ESTACI√ìN': estacion_seleccionada, **item_spec_row}
                    item_data = generar_pregunta_con_seleccion(gen_model_name, audit_model_name, current_fila_datos, criterios_para_preguntas, manual_reglas_texto, informacion_adicional_usuario, prompt_bloom_adicional, prompt_construccion_adicional, prompt_especifico_adicional, prompt_auditor_adicional, contexto_general_estacion)
                    if item_data:
                        processed_items_list.append(item_data)
                    progress_bar.progress((i + 1) / len(unique_procesos))
                st.success("Proceso completado.")

            else:
                st.info(f"Generando √≠tem individual para: {nanohabilidad_seleccionada}")
                item_data = generar_pregunta_con_seleccion(gen_model_name, audit_model_name, df_item_seleccionado.iloc[0], criterios_para_preguntas, manual_reglas_texto, informacion_adicional_usuario, prompt_bloom_adicional, prompt_construccion_adicional, prompt_especifico_adicional, prompt_auditor_adicional)
                if item_data:
                    processed_items_list.append(item_data)
                    st.success(f"√çtem generado. Dictamen: {item_data.get('final_audit_status')}")

            st.session_state['processed_items_list'] = processed_items_list
            
            if processed_items_list:
                st.subheader("Resumen del Primer √çtem Procesado:")
                first_item = processed_items_list[0]
                st.markdown(first_item['item_text'])
                st.info(f"Dictamen: {first_item['final_audit_status']}")
            else:
                st.error("No se pudo generar ning√∫n √≠tem.")
        
        st.header("Exportar Resultados")
        if 'processed_items_list' in st.session_state and st.session_state['processed_items_list']:
            num_items = len(st.session_state['processed_items_list'])
            st.write(f"Hay {num_items} √≠tem(s) listos para exportar.")
            
            word_buffer = exportar_a_word(st.session_state['processed_items_list'])
            st.download_button(
                label="Descargar √çtem(s) en Word", data=word_buffer,
                file_name=f"items_{estacion_seleccionada.replace(' ', '_')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

            combined_prompts_content = ""
            for i, item_data in enumerate(st.session_state['processed_items_list']):
                combined_prompts_content += f"--- √çTEM #{i+1} ({item_data['classification']['Proceso Cognitivo']}) ---\n"
                combined_prompts_content += f"--- PROMPT GENERADOR ---\n{item_data.get('generation_prompt_used', 'N/A')}\n\n"
                combined_prompts_content += f"--- PROMPT AUDITOR ---\n{item_data.get('auditor_prompt_used', 'N/A')}\n\n{'='*80}\n\n"

            st.download_button(
                label="Descargar Prompts como TXT", data=combined_prompts_content.encode('utf-8'),
                file_name=f"prompts_{estacion_seleccionada.replace(' ', '_')}.txt", mime="text/plain"
            )
